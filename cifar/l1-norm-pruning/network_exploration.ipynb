{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/hguan2/anaconda2/envs/distiller/lib/python3.5/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "using GPU: True\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x7fa430037050>"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import distiller \n",
    "import numpy as np\n",
    "import os, collections\n",
    "import bitstring \n",
    "import time \n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.autograd import Variable\n",
    "from torchvision import datasets, transforms\n",
    "import torch.nn.functional as F\n",
    "import torchvision \n",
    "import models \n",
    "from matplotlib import pyplot as plt\n",
    "from eval_util import test_imagenet \n",
    "# import multiprocessing \n",
    "%matplotlib inline\n",
    "\n",
    "from fault_injection import * \n",
    "\n",
    "import matplotlib \n",
    "matplotlib.rcParams['pdf.fonttype'] = 42\n",
    "\n",
    "print('using GPU:', torch.cuda.is_available())\n",
    "torch.manual_seed(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/hguan2/anaconda2/envs/distiller/lib/python3.5/site-packages/torchvision/models/squeezenet.py:94: UserWarning: nn.init.kaiming_uniform is now deprecated in favor of nn.init.kaiming_uniform_.\n",
      "  init.kaiming_uniform(m.weight.data)\n",
      "/home/hguan2/anaconda2/envs/distiller/lib/python3.5/site-packages/torchvision/models/squeezenet.py:92: UserWarning: nn.init.normal is now deprecated in favor of nn.init.normal_.\n",
      "  init.normal(m.weight.data, mean=0.0, std=0.01)\n"
     ]
    }
   ],
   "source": [
    "# check the weight distribution of other pre-trained models in torch vision\n",
    "# use resnet18, alexnet, vgg16 \n",
    "\n",
    "pretrained_models = {'resnet18': torchvision.models.resnet18(pretrained=True),\n",
    "                     'resnet34': torchvision.models.resnet34(pretrained=True),\n",
    "                     'alexnet': torchvision.models.alexnet(pretrained=True),\n",
    "                     'squeezenet': torchvision.models.squeezenet1_0(pretrained=True),\n",
    "                     'vgg16':  torchvision.models.vgg16(pretrained=True), \n",
    "                      'vgg16_bn':  torchvision.models.vgg16_bn(pretrained=True), \n",
    "#                      'densenet':  torchvision.models.densenet161(pretrained=True),\n",
    "                     'inception_v3':  torchvision.models.inception_v3(pretrained=True),\n",
    "                    }\n",
    "\n",
    "model_name = 'vgg16'\n",
    "# model_name = 'resnet18'\n",
    "# model_name = 'squeezenet'\n",
    "model = pretrained_models[model_name]\n",
    "# print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check model weight size is a multiple of eight\n",
    "# for name, param in model.named_parameters():\n",
    "#     if len(param.size()) < 2:\n",
    "#         continue \n",
    "#     length = param.nelement()\n",
    "#     assert length%8 == 0, '#values not equal to 8X: %d' %(length)\n",
    "#     print(name, param.size(), '8X?', length%8 == 0)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# post train quantization \n",
    "quantizer = distiller.quantization.PostTrainLinearQuantizer(model)\n",
    "quantizer.prepare_model()\n",
    "# print(model)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0, features.0.wrapped_module.weight, (64, 3, 3, 3), 1728, 43, 282\n",
      "1, features.2.wrapped_module.weight, (64, 64, 3, 3), 36864, 112, 1090\n",
      "2, features.5.wrapped_module.weight, (128, 64, 3, 3), 73728, 47, 977\n",
      "3, features.7.wrapped_module.weight, (128, 128, 3, 3), 147456, 178, 4312\n",
      "4, features.10.wrapped_module.weight, (256, 128, 3, 3), 294912, 12, 427\n",
      "5, features.12.wrapped_module.weight, (256, 256, 3, 3), 589824, 24, 1128\n",
      "6, features.14.wrapped_module.weight, (256, 256, 3, 3), 589824, 5, 255\n",
      "7, features.17.wrapped_module.weight, (512, 256, 3, 3), 1179648, 34, 890\n",
      "8, features.19.wrapped_module.weight, (512, 512, 3, 3), 2359296, 75, 2954\n",
      "9, features.21.wrapped_module.weight, (512, 512, 3, 3), 2359296, 216, 8162\n",
      "10, features.24.wrapped_module.weight, (512, 512, 3, 3), 2359296, 17, 1299\n",
      "11, features.26.wrapped_module.weight, (512, 512, 3, 3), 2359296, 11, 2977\n",
      "12, features.28.wrapped_module.weight, (512, 512, 3, 3), 2359296, 1665, 100482\n",
      "13, classifier.0.wrapped_module.weight, (4096, 25088), 102760448, 252, 462390\n",
      "14, classifier.3.wrapped_module.weight, (4096, 4096), 16777216, 42675, 2104427\n",
      "15, classifier.6.wrapped_module.weight, (1000, 4096), 4096000, 2321, 317776\n"
     ]
    }
   ],
   "source": [
    "# save value to binary files \n",
    "def get_named_weights(model):\n",
    "    named_params = [] \n",
    "    for name, param in model.named_parameters():\n",
    "        if len(param.size()) >= 2:\n",
    "            named_params.append((name, param)) \n",
    "    return named_params \n",
    "def large_value_indexes(tensor, thr=64):\n",
    "    '''tensor is torch tensor, thr is the large value threshold'''\n",
    "    tensor = tensor.view(-1)\n",
    "    indexes = torch.nonzero((tensor > thr-1) + (tensor < -thr)).view(-1)\n",
    "    return indexes \n",
    "\n",
    "def check_directory(path):\n",
    "    if not os.path.isdir(path):\n",
    "        os.makedirs(path)\n",
    "\n",
    "named_params = get_named_weights(model)\n",
    "datapath = os.path.join('./weights/', model_name)\n",
    "check_directory(datapath)\n",
    "\n",
    "\n",
    "weight_id =  0 \n",
    "meta = '' \n",
    "for name, param in named_params:\n",
    "\n",
    "    tensor = param.data\n",
    "    shape = tuple(tensor.size())\n",
    "    size = tensor.nelement()\n",
    "#     largerThan64 = large_value_number(param.data, thr=64)\n",
    "    largerThan32 = large_value_number(param.data, thr=32)\n",
    "\n",
    "    # record data meta info \n",
    "    info = '%d, %s, %s, %d, %d' %(weight_id, name, shape, size, largerThan32)\n",
    "    meta += info+'\\n' \n",
    "    print(info)\n",
    "\n",
    "    # save tensor as binary\n",
    "    tensor1d = tensor.view(-1).numpy().astype(np.int8)\n",
    "    np.savetxt(os.path.join(datapath, '%d.txt' %(weight_id)), tensor1d, fmt='%d')\n",
    "\n",
    "    weight_id += 1\n",
    "\n",
    "with open(os.path.join(datapath, 'meta.txt'), 'w') as f:\n",
    "    f.write('weight_id, name, shape, size, largerThan32\\n')\n",
    "    f.write(meta)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# def test_large_value_percentage():\n",
    "#     tensor = torch.randint(-100, 100, size=(10, ))\n",
    "#     print(tensor)\n",
    "#     print(large_value_percentage(tensor))\n",
    "# test_large_value_percentage()\n",
    "    \n",
    "# named_params = get_named_weights(model)\n",
    "# n_larges = [] \n",
    "# weight_id = 0 \n",
    "# for name, param in named_params:\n",
    "#     tensor = param.data \n",
    "#     size = tensor.nelement()\n",
    "#     num_large_values = large_value_number(tensor, 64)\n",
    "#     n_larges.append((weight_id, name, num_large_values, round(num_large_values/size, 6)))\n",
    "#     weight_id += 1\n",
    "    \n",
    "# # sort based on the number of large values \n",
    "# sorted_n_larges = sorted(n_larges, key = lambda x: x[2], reverse = True)\n",
    "# for item in sorted_n_larges:\n",
    "#     print(item)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def large_value_max_distance(tensor):\n",
    "#     '''tensor has to be 1-d tensor'''\n",
    "#     size = tensor.nelement()\n",
    "#     tensor = tensor.view(-1)\n",
    "#     indexes = torch.nonzero((tensor > 63) + (tensor < -64)).view(-1)\n",
    "#     diff = indexes[1:] - indexes[:-1]\n",
    "#     d = torch.max(diff)\n",
    "#     return d.item() \n",
    "\n",
    "# # print the maximum distance between large values \n",
    "# weight_id = 0 \n",
    "# for name, param in named_params:\n",
    "#     print(weight_id, name, large_value_max_distance(param.data))\n",
    "#     weight_id += 1\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check the distribution of parameters \n",
    "# thr = 32\n",
    "# layer_id = 0 \n",
    "# for param_name, param in model.named_parameters():\n",
    "#     if len(param.size()) < 2:\n",
    "#         continue\n",
    "#     counter = collections.Counter(np.abs(param.data.cpu().numpy().ravel())//thr)\n",
    "#     tmp = sorted(counter.items(), key=lambda x: x[0])\n",
    "#     values, counts = zip(*tmp)\n",
    "#     percentages = [count/sum(list(counts)) for count in counts]\n",
    "#     bar = plt.bar(values, percentages)\n",
    "#     for rect in bar:\n",
    "#         height = rect.get_height()\n",
    "#         plt.text(rect.get_x() + rect.get_width()/2.0, height, '%.4f%%' %(height*100), ha='center', va='bottom')\n",
    "# #     print(['%.2f' %(p) for p in percentages])\n",
    "#     #plt.hist(param.data.cpu().numpy().ravel(), bins=10, density=True)\n",
    "#     plt.xticks(values, [str(int(v)*thr+thr) for v in values])\n",
    "#     plt.title('layer_id:'+str(layer_id) + ', '+ str(tuple(param.size())))\n",
    "# #     plt.grid()\n",
    "#     plt.ylim(0, 1.1)\n",
    "#     plt.show()\n",
    "#     layer_id += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check the distribution of parameters all weights\n",
    "# thr = 32\n",
    "# total_values, num_weights = 0, 0 \n",
    "# counter = collections.Counter()\n",
    "# for param_name, param in model.named_parameters():\n",
    "#     total_values += param.nelement()\n",
    "#     if len(param.size()) < 2:\n",
    "#         continue\n",
    "#     num_weights += param.nelement()\n",
    "#     counter.update(collections.Counter(np.abs(param.data.cpu().numpy().ravel())//thr + 1))\n",
    "    \n",
    "# tmp = sorted(counter.items(), key=lambda x: x[0])\n",
    "# values, counts = zip(*tmp)\n",
    "# total_weights = sum(list(counts))\n",
    "\n",
    "# assert total_weights == num_weights\n",
    "# print('#weights:', total_weights, ', #params:', total_values, 'percentage:', '%.6f' %(num_weights/total_values))\n",
    "\n",
    "# percentages = [count/total_weights for count in counts]\n",
    "# bar = plt.bar(values, percentages)\n",
    "# for rect in bar:\n",
    "#     height = rect.get_height()\n",
    "#     plt.text(rect.get_x() + rect.get_width()/2.0, height, '%.4f%%' %(height*100), ha='center', va='bottom')\n",
    "# #     print(['%.2f' %(p) for p in percentages])\n",
    "# #plt.hist(param.data.cpu().numpy().ravel(), bins=10, density=True)\n",
    "# # plt.xticks(values, [str(int(v)*thr) for v in values])\n",
    "# plt.xticks(values, ['[0, 32]', '[32, 64]', '[64, 96]', '[96, 128]'])\n",
    "# plt.title(model_name)\n",
    "# #     plt.grid()\n",
    "# plt.ylim(0, 1.1)\n",
    "# plt.show()\n",
    "\n",
    "# figdir = './figures/weight_distribution/'\n",
    "# figname = model_name+'_int8_weight_distribution.pdf'\n",
    "# plt.savefig(os.path.join(figdir, figname), bbox_inches='tight')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "## load gradual_encoding_absolute result \n",
    "# lossy_encoding_results = {\n",
    "#     'vgg16': './logs/vgg16/imagenet/int8/gradual_encoding_absolute',\n",
    "#     'resnet18': './logs/resnet18/imagenet/int8/gradual_encoding_absolute',\n",
    "#     'squeezenet': './logs/squeezenet/imagenet/int8/gradual_encoding_absolute',\n",
    "# }\n",
    "\n",
    "\n",
    "# def parse_gradual_encoding_absolute_log(log_path):\n",
    "#     res = [] \n",
    "#     with open(os.path.join(log_path, 'logs.txt'), 'r') as f:\n",
    "#         lines = f.readlines()\n",
    "#         for line in lines:\n",
    "#             line = line.strip()\n",
    "#             if line:\n",
    "#                 items = line.split(',')\n",
    "#                 for item in items:\n",
    "#                     if 'n_large' in item:\n",
    "#                         n_large = int(item.split(':')[-1])\n",
    "#                     if 'name' in item:\n",
    "#                         name = item.split(':')[-1].strip()\n",
    "#                     if 'accuracy' in item:\n",
    "#                         accuracy = float(item.split(':')[-1])\n",
    "#                 res.append((accuracy, name, n_large))\n",
    "                \n",
    "#     return res \n",
    "\n",
    "   \n",
    "\n",
    "# log_path = lossy_encoding_results[model_name]\n",
    "# res = parse_gradual_encoding_absolute_log(log_path)\n",
    "\n",
    "# accuracies = [] \n",
    "# for a, b in zip(sorted_n_larges, res):\n",
    "#     weight_id = a[0]\n",
    "#     accuracy = b[0]\n",
    "#     name = a[1]\n",
    "#     n_large = a[2]\n",
    "#     assert a[1] == b[1], 'param name not equal: %s, %s' %(a[1], b[1])\n",
    "#     assert a[2] == b[2], 'param n_large not equal: %d, %d' %(a[2], b[2])\n",
    "#     accuracies.append((weight_id, name, n_large, accuracy))\n",
    "# for item in accuracies:\n",
    "#     print(item)\n",
    "            \n",
    "            \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from right to the left, find the k for sorted_layers[:k].\n",
    "# fault_free_accuracies = {\n",
    "    \n",
    "#     'vgg16': 79.36,\n",
    "#     'resnet18': 76.46,\n",
    "#     'squeezenet': 66.86,\n",
    "# }\n",
    "# max_acc = fault_free_accuracies[model_name]\n",
    "# min_acc = 0\n",
    "# accuracy_to_ids = [] \n",
    "# for i in range(len(accuracies)-1, -1, -1):\n",
    "#     accuracy = accuracies[i][-1]\n",
    "#     if accuracy > min_acc:\n",
    "#         accuracy_to_ids.append((accuracy, [x[0] for x in accuracies[:i+1]]))\n",
    "#         min_acc = accuracy \n",
    "\n",
    "# # add the option of all weights are lossless \n",
    "# accuracy_to_ids.append((0, []))\n",
    "    \n",
    "# for item in accuracy_to_ids:\n",
    "#     print(item)\n",
    "\n",
    "# # with open(os.path.join(log_path, 'steps.txt'), 'w') as f:\n",
    "# #     for item in accuracy_to_ids:\n",
    "# #         s = \"%.2f\" %(item[0]) + ': '+ ', '.join([str(x) for x in item[1]]) + '\\n'\n",
    "# #         f.write(s) \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
