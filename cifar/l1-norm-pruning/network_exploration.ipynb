{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "using GPU: True\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x7f9d9e3e10b0>"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import distiller \n",
    "import numpy as np\n",
    "import os, collections\n",
    "import bitstring \n",
    "import time \n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.autograd import Variable\n",
    "from torchvision import datasets, transforms\n",
    "import torch.nn.functional as F\n",
    "import torchvision \n",
    "import models \n",
    "from matplotlib import pyplot as plt\n",
    "from eval_util import test_imagenet \n",
    "# import multiprocessing \n",
    "%matplotlib inline\n",
    "\n",
    "from fault_injection import * \n",
    "\n",
    "import matplotlib \n",
    "matplotlib.rcParams['pdf.fonttype'] = 42\n",
    "\n",
    "print('using GPU:', torch.cuda.is_available())\n",
    "torch.manual_seed(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/hguan2/anaconda2/envs/distiller/lib/python3.5/site-packages/torchvision/models/squeezenet.py:94: UserWarning: nn.init.kaiming_uniform is now deprecated in favor of nn.init.kaiming_uniform_.\n",
      "  init.kaiming_uniform(m.weight.data)\n",
      "/home/hguan2/anaconda2/envs/distiller/lib/python3.5/site-packages/torchvision/models/squeezenet.py:92: UserWarning: nn.init.normal is now deprecated in favor of nn.init.normal_.\n",
      "  init.normal(m.weight.data, mean=0.0, std=0.01)\n"
     ]
    }
   ],
   "source": [
    "# check the weight distribution of other pre-trained models in torch vision\n",
    "# use resnet18, alexnet, vgg16 \n",
    "\n",
    "pretrained_models = {'resnet18': torchvision.models.resnet18(pretrained=True),\n",
    "                     'resnet34': torchvision.models.resnet34(pretrained=True),\n",
    "                     'alexnet': torchvision.models.alexnet(pretrained=True),\n",
    "                     'squeezenet': torchvision.models.squeezenet1_0(pretrained=True),\n",
    "                     'vgg16':  torchvision.models.vgg16(pretrained=True), \n",
    "                      'vgg16_bn':  torchvision.models.vgg16_bn(pretrained=True), \n",
    "#                      'densenet':  torchvision.models.densenet161(pretrained=True),\n",
    "                     'inception_v3':  torchvision.models.inception_v3(pretrained=True),\n",
    "                    }\n",
    "# for model_name, pretrained_model in pretrained_models.items():\n",
    "#     tensor = [param.data.cpu().numpy().ravel() for param in pretrained_model.parameters()]\n",
    "#     tensor = np.concatenate(tensor)\n",
    "#     minv, maxv = np.min(tensor), np.max(tensor)\n",
    "#     num_values = tensor.shape[0]\n",
    "#     plt.hist(tensor, bins=10000)\n",
    "#     plt.title(model_name+ ':[%f, %f], #=%.1f(M)' %(minv, maxv, num_values/10e6))\n",
    "#     plt.show()\n",
    "\n",
    "# model_name = 'vgg16'\n",
    "# model_name = 'resnet18'\n",
    "model_name = 'squeezenet'\n",
    "model = pretrained_models[model_name]\n",
    "# print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "features.0.weight torch.Size([96, 3, 7, 7]) 8X? True\n",
      "features.3.squeeze.weight torch.Size([16, 96, 1, 1]) 8X? True\n",
      "features.3.expand1x1.weight torch.Size([64, 16, 1, 1]) 8X? True\n",
      "features.3.expand3x3.weight torch.Size([64, 16, 3, 3]) 8X? True\n",
      "features.4.squeeze.weight torch.Size([16, 128, 1, 1]) 8X? True\n",
      "features.4.expand1x1.weight torch.Size([64, 16, 1, 1]) 8X? True\n",
      "features.4.expand3x3.weight torch.Size([64, 16, 3, 3]) 8X? True\n",
      "features.5.squeeze.weight torch.Size([32, 128, 1, 1]) 8X? True\n",
      "features.5.expand1x1.weight torch.Size([128, 32, 1, 1]) 8X? True\n",
      "features.5.expand3x3.weight torch.Size([128, 32, 3, 3]) 8X? True\n",
      "features.7.squeeze.weight torch.Size([32, 256, 1, 1]) 8X? True\n",
      "features.7.expand1x1.weight torch.Size([128, 32, 1, 1]) 8X? True\n",
      "features.7.expand3x3.weight torch.Size([128, 32, 3, 3]) 8X? True\n",
      "features.8.squeeze.weight torch.Size([48, 256, 1, 1]) 8X? True\n",
      "features.8.expand1x1.weight torch.Size([192, 48, 1, 1]) 8X? True\n",
      "features.8.expand3x3.weight torch.Size([192, 48, 3, 3]) 8X? True\n",
      "features.9.squeeze.weight torch.Size([48, 384, 1, 1]) 8X? True\n",
      "features.9.expand1x1.weight torch.Size([192, 48, 1, 1]) 8X? True\n",
      "features.9.expand3x3.weight torch.Size([192, 48, 3, 3]) 8X? True\n",
      "features.10.squeeze.weight torch.Size([64, 384, 1, 1]) 8X? True\n",
      "features.10.expand1x1.weight torch.Size([256, 64, 1, 1]) 8X? True\n",
      "features.10.expand3x3.weight torch.Size([256, 64, 3, 3]) 8X? True\n",
      "features.12.squeeze.weight torch.Size([64, 512, 1, 1]) 8X? True\n",
      "features.12.expand1x1.weight torch.Size([256, 64, 1, 1]) 8X? True\n",
      "features.12.expand3x3.weight torch.Size([256, 64, 3, 3]) 8X? True\n",
      "classifier.1.weight torch.Size([1000, 512, 1, 1]) 8X? True\n"
     ]
    }
   ],
   "source": [
    "# check model weight size is a multiple of eight\n",
    "for name, param in model.named_parameters():\n",
    "    if len(param.size()) < 2:\n",
    "        continue \n",
    "    length = param.nelement()\n",
    "    print(name, param.size(), '8X?', length%8 == 0)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "# valdir = '/home/hguan2/datasets/imagenet/val'\n",
    "# acc1 = test_imagenet(model, valdir, num_batches=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "# post train quantization \n",
    "quantizer = distiller.quantization.PostTrainLinearQuantizer(model)\n",
    "quantizer.prepare_model()\n",
    "# print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "# acc1 = test_imagenet(model, valdir, num_batches=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "# use SEC_DED code to encode tensor inplace. use the LSB to record the parity bit\n",
    "# model.cpu() \n",
    "# for name, param in model.named_parameters():\n",
    "#     if len(param.size()) < 2:\n",
    "#         continue \n",
    "#     tensor = param.data\n",
    "    \n",
    "#     start = time.time()\n",
    "#     secded_encode(tensor)\n",
    "#     end = time.time() - start\n",
    "#     print('encode tensor name:%s, size:%s, time(s):%s' %(name, tensor.nelement(), end))\n",
    "    \n",
    "# acc1 = test_imagenet(model, valdir, num_batches=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(25, 'classifier.1.wrapped_module.weight', 1286)\n",
      "(23, 'features.12.expand1x1.wrapped_module.weight', 262)\n",
      "(13, 'features.8.squeeze.wrapped_module.weight', 123)\n",
      "(0, 'features.0.wrapped_module.weight', 120)\n",
      "(6, 'features.4.expand3x3.wrapped_module.weight', 117)\n",
      "(20, 'features.10.expand1x1.wrapped_module.weight', 106)\n",
      "(11, 'features.7.expand1x1.wrapped_module.weight', 78)\n",
      "(19, 'features.10.squeeze.wrapped_module.weight', 71)\n",
      "(4, 'features.4.squeeze.wrapped_module.weight', 69)\n",
      "(16, 'features.9.squeeze.wrapped_module.weight', 59)\n",
      "(22, 'features.12.squeeze.wrapped_module.weight', 59)\n",
      "(2, 'features.3.expand1x1.wrapped_module.weight', 51)\n",
      "(1, 'features.3.squeeze.wrapped_module.weight', 46)\n",
      "(18, 'features.9.expand3x3.wrapped_module.weight', 40)\n",
      "(17, 'features.9.expand1x1.wrapped_module.weight', 39)\n",
      "(14, 'features.8.expand1x1.wrapped_module.weight', 35)\n",
      "(8, 'features.5.expand1x1.wrapped_module.weight', 31)\n",
      "(7, 'features.5.squeeze.wrapped_module.weight', 28)\n",
      "(12, 'features.7.expand3x3.wrapped_module.weight', 28)\n",
      "(3, 'features.3.expand3x3.wrapped_module.weight', 24)\n",
      "(24, 'features.12.expand3x3.wrapped_module.weight', 23)\n",
      "(15, 'features.8.expand3x3.wrapped_module.weight', 20)\n",
      "(5, 'features.4.expand1x1.wrapped_module.weight', 19)\n",
      "(21, 'features.10.expand3x3.wrapped_module.weight', 13)\n",
      "(9, 'features.5.expand3x3.wrapped_module.weight', 3)\n",
      "(10, 'features.7.squeeze.wrapped_module.weight', 3)\n"
     ]
    }
   ],
   "source": [
    "def get_named_weights(model):\n",
    "    named_params = [] \n",
    "    for name, param in model.named_parameters():\n",
    "        if len(param.size()) >= 2:\n",
    "            named_params.append((name, param)) \n",
    "    return named_params \n",
    "\n",
    "def large_value_number(tensor):\n",
    "    size = tensor.nelement()\n",
    "    num_large_values = torch.nonzero((tensor > 63) + (tensor < -64)).size()[0]\n",
    "#     print(num_large_values)\n",
    "    return num_large_values # num_large_values*1.0/size \n",
    "\n",
    "# def test_large_value_percentage():\n",
    "#     tensor = torch.randint(-100, 100, size=(10, ))\n",
    "#     print(tensor)\n",
    "#     print(large_value_percentage(tensor))\n",
    "# test_large_value_percentage()\n",
    "    \n",
    "named_params = get_named_weights(model)\n",
    "\n",
    "n_larges = [] \n",
    "weight_id = 0 \n",
    "for name, param in named_params:\n",
    "    n_larges.append((weight_id, name, large_value_number(param.data)))\n",
    "    weight_id += 1\n",
    "sorted_n_larges = sorted(n_larges, key = lambda x: x[-1], reverse = True)\n",
    "for item in sorted_n_larges:\n",
    "    print(item)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check the distribution of parameters \n",
    "# thr = 32\n",
    "# layer_id = 0 \n",
    "# for param_name, param in model.named_parameters():\n",
    "#     if len(param.size()) < 2:\n",
    "#         continue\n",
    "#     counter = collections.Counter(np.abs(param.data.cpu().numpy().ravel())//thr)\n",
    "#     tmp = sorted(counter.items(), key=lambda x: x[0])\n",
    "#     values, counts = zip(*tmp)\n",
    "#     percentages = [count/sum(list(counts)) for count in counts]\n",
    "#     bar = plt.bar(values, percentages)\n",
    "#     for rect in bar:\n",
    "#         height = rect.get_height()\n",
    "#         plt.text(rect.get_x() + rect.get_width()/2.0, height, '%.4f%%' %(height*100), ha='center', va='bottom')\n",
    "# #     print(['%.2f' %(p) for p in percentages])\n",
    "#     #plt.hist(param.data.cpu().numpy().ravel(), bins=10, density=True)\n",
    "#     plt.xticks(values, [str(int(v)*thr+thr) for v in values])\n",
    "#     plt.title('layer_id:'+str(layer_id) + ', '+ str(tuple(param.size())))\n",
    "# #     plt.grid()\n",
    "#     plt.ylim(0, 1.1)\n",
    "#     plt.show()\n",
    "#     layer_id += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check the distribution of parameters all weights\n",
    "# thr = 32\n",
    "# total_values, num_weights = 0, 0 \n",
    "# counter = collections.Counter()\n",
    "# for param_name, param in model.named_parameters():\n",
    "#     total_values += param.nelement()\n",
    "#     if len(param.size()) < 2:\n",
    "#         continue\n",
    "#     num_weights += param.nelement()\n",
    "#     counter.update(collections.Counter(np.abs(param.data.cpu().numpy().ravel())//thr + 1))\n",
    "    \n",
    "# tmp = sorted(counter.items(), key=lambda x: x[0])\n",
    "# values, counts = zip(*tmp)\n",
    "# total_weights = sum(list(counts))\n",
    "\n",
    "# assert total_weights == num_weights\n",
    "# print('#weights:', total_weights, ', #params:', total_values, 'percentage:', '%.6f' %(num_weights/total_values))\n",
    "\n",
    "# percentages = [count/total_weights for count in counts]\n",
    "# bar = plt.bar(values, percentages)\n",
    "# for rect in bar:\n",
    "#     height = rect.get_height()\n",
    "#     plt.text(rect.get_x() + rect.get_width()/2.0, height, '%.4f%%' %(height*100), ha='center', va='bottom')\n",
    "# #     print(['%.2f' %(p) for p in percentages])\n",
    "# #plt.hist(param.data.cpu().numpy().ravel(), bins=10, density=True)\n",
    "# # plt.xticks(values, [str(int(v)*thr) for v in values])\n",
    "# plt.xticks(values, ['[0, 32]', '[32, 64]', '[64, 96]', '[96, 128]'])\n",
    "# plt.title(model_name)\n",
    "# #     plt.grid()\n",
    "# plt.ylim(0, 1.1)\n",
    "# plt.show()\n",
    "\n",
    "# figdir = './figures/weight_distribution/'\n",
    "# figname = model_name+'_int8_weight_distribution.pdf'\n",
    "# plt.savefig(os.path.join(figdir, figname), bbox_inches='tight')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(25, 'classifier.1.wrapped_module.weight', 1286, 67.0)\n",
      "(23, 'features.12.expand1x1.wrapped_module.weight', 262, 66.86)\n",
      "(13, 'features.8.squeeze.wrapped_module.weight', 123, 66.64)\n",
      "(0, 'features.0.wrapped_module.weight', 120, 66.26)\n",
      "(6, 'features.4.expand3x3.wrapped_module.weight', 117, 66.2)\n",
      "(20, 'features.10.expand1x1.wrapped_module.weight', 106, 66.42)\n",
      "(11, 'features.7.expand1x1.wrapped_module.weight', 78, 66.26)\n",
      "(19, 'features.10.squeeze.wrapped_module.weight', 71, 66.04)\n",
      "(4, 'features.4.squeeze.wrapped_module.weight', 69, 66.18)\n",
      "(16, 'features.9.squeeze.wrapped_module.weight', 59, 66.16)\n",
      "(22, 'features.12.squeeze.wrapped_module.weight', 59, 65.9)\n",
      "(2, 'features.3.expand1x1.wrapped_module.weight', 51, 66.0)\n",
      "(1, 'features.3.squeeze.wrapped_module.weight', 46, 65.78)\n",
      "(18, 'features.9.expand3x3.wrapped_module.weight', 40, 65.86)\n",
      "(17, 'features.9.expand1x1.wrapped_module.weight', 39, 65.88)\n",
      "(14, 'features.8.expand1x1.wrapped_module.weight', 35, 65.68)\n",
      "(8, 'features.5.expand1x1.wrapped_module.weight', 31, 65.72)\n",
      "(7, 'features.5.squeeze.wrapped_module.weight', 28, 65.9)\n",
      "(12, 'features.7.expand3x3.wrapped_module.weight', 28, 65.68)\n",
      "(3, 'features.3.expand3x3.wrapped_module.weight', 24, 65.44)\n",
      "(24, 'features.12.expand3x3.wrapped_module.weight', 23, 65.5)\n",
      "(15, 'features.8.expand3x3.wrapped_module.weight', 20, 65.52)\n",
      "(5, 'features.4.expand1x1.wrapped_module.weight', 19, 65.18)\n",
      "(21, 'features.10.expand3x3.wrapped_module.weight', 13, 65.28)\n",
      "(9, 'features.5.expand3x3.wrapped_module.weight', 3, 64.8)\n",
      "(10, 'features.7.squeeze.wrapped_module.weight', 3, 64.96)\n"
     ]
    }
   ],
   "source": [
    "## load gradual_encoding_absolute result \n",
    "lossy_encoding_results = {\n",
    "    'vgg16': './logs/vgg16/imagenet/int8/gradual_encoding_absolute',\n",
    "    'resnet18': './logs/resnet18/imagenet/int8/gradual_encoding_absolute',\n",
    "    'squeezenet': './logs/squeezenet/imagenet/int8/gradual_encoding_absolute',\n",
    "}\n",
    "\n",
    "\n",
    "def parse_gradual_encoding_absolute_log(log_path):\n",
    "    res = [] \n",
    "    with open(os.path.join(log_path, 'logs.txt'), 'r') as f:\n",
    "        lines = f.readlines()\n",
    "        for line in lines:\n",
    "            line = line.strip()\n",
    "            if line:\n",
    "                items = line.split(',')\n",
    "                for item in items:\n",
    "                    if 'n_large' in item:\n",
    "                        n_large = int(item.split(':')[-1])\n",
    "                    if 'name' in item:\n",
    "                        name = item.split(':')[-1].strip()\n",
    "                    if 'accuracy' in item:\n",
    "                        accuracy = float(item.split(':')[-1])\n",
    "                res.append((accuracy, name, n_large))\n",
    "                \n",
    "    return res \n",
    "\n",
    "   \n",
    "\n",
    "log_path = lossy_encoding_results[model_name]\n",
    "res = parse_gradual_encoding_absolute_log(log_path)\n",
    "\n",
    "accuracies = [] \n",
    "for a, b in zip(sorted_n_larges, res):\n",
    "    weight_id = a[0]\n",
    "    accuracy = b[0]\n",
    "    name = a[1]\n",
    "    n_large = a[2]\n",
    "    assert a[1] == b[1], 'param name not equal: %s, %s' %(a[1], b[1])\n",
    "    assert a[2] == b[2], 'param n_large not equal: %d, %d' %(a[2], b[2])\n",
    "    accuracies.append((weight_id, name, n_large, accuracy))\n",
    "for item in accuracies:\n",
    "    print(item)\n",
    "            \n",
    "            \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(64.96, [25, 23, 13, 0, 6, 20, 11, 19, 4, 16, 22, 2, 1, 18, 17, 14, 8, 7, 12, 3, 24, 15, 5, 21, 9, 10])\n",
      "(65.28, [25, 23, 13, 0, 6, 20, 11, 19, 4, 16, 22, 2, 1, 18, 17, 14, 8, 7, 12, 3, 24, 15, 5, 21])\n",
      "(65.52, [25, 23, 13, 0, 6, 20, 11, 19, 4, 16, 22, 2, 1, 18, 17, 14, 8, 7, 12, 3, 24, 15])\n",
      "(65.68, [25, 23, 13, 0, 6, 20, 11, 19, 4, 16, 22, 2, 1, 18, 17, 14, 8, 7, 12])\n",
      "(65.9, [25, 23, 13, 0, 6, 20, 11, 19, 4, 16, 22, 2, 1, 18, 17, 14, 8, 7])\n",
      "(66.0, [25, 23, 13, 0, 6, 20, 11, 19, 4, 16, 22, 2])\n",
      "(66.16, [25, 23, 13, 0, 6, 20, 11, 19, 4, 16])\n",
      "(66.18, [25, 23, 13, 0, 6, 20, 11, 19, 4])\n",
      "(66.26, [25, 23, 13, 0, 6, 20, 11])\n",
      "(66.42, [25, 23, 13, 0, 6, 20])\n",
      "(66.64, [25, 23, 13])\n",
      "(66.86, [25, 23])\n",
      "(67.0, [25])\n",
      "(0, [])\n"
     ]
    }
   ],
   "source": [
    "# from right to the left, find the k for sorted_layers[:k].\n",
    "fault_free_accuracies = {\n",
    "    \n",
    "    'vgg16': 79.36,\n",
    "    'resnet18': 76.46,\n",
    "    'squeezenet': 66.86,\n",
    "}\n",
    "max_acc = fault_free_accuracies[model_name]\n",
    "min_acc = 0\n",
    "accuracy_to_ids = [] \n",
    "for i in range(len(accuracies)-1, -1, -1):\n",
    "    accuracy = accuracies[i][-1]\n",
    "    if accuracy > min_acc:\n",
    "        accuracy_to_ids.append((accuracy, [x[0] for x in accuracies[:i+1]]))\n",
    "        min_acc = accuracy \n",
    "\n",
    "# add the option of all weights are lossless \n",
    "accuracy_to_ids.append((0, []))\n",
    "    \n",
    "for item in accuracy_to_ids:\n",
    "    print(item)\n",
    "\n",
    "with open(os.path.join(log_path, 'steps.txt'), 'w') as f:\n",
    "    for item in accuracy_to_ids:\n",
    "        s = \"%.2f\" %(item[0]) + ': '+ ', '.join([str(x) for x in item[1]]) + '\\n'\n",
    "        f.write(s) \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
