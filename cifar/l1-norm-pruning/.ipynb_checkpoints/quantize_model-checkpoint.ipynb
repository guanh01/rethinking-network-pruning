{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/hguan2/anaconda2/envs/distiller/lib/python3.5/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "using GPU: True\n"
     ]
    }
   ],
   "source": [
    "import distiller \n",
    "import numpy as np\n",
    "import os\n",
    "import bitstring \n",
    "import time \n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.autograd import Variable\n",
    "from torchvision import datasets, transforms\n",
    "import torch.nn.functional as F\n",
    "\n",
    "import models \n",
    "from matplotlib import pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "print('using GPU:', torch.cuda.is_available())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_batch_size = 256\n",
    "kwargs = {'num_workers': 1, 'pin_memory': True} if torch.cuda.is_available() else {}\n",
    "test_loader = torch.utils.data.DataLoader(\n",
    "    datasets.CIFAR10('./data.cifar10', train=False, transform=transforms.Compose([\n",
    "                       transforms.ToTensor(),\n",
    "                       transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010))\n",
    "                   ])),\n",
    "    batch_size=test_batch_size, shuffle=False, **kwargs)\n",
    "\n",
    "def load_checkpoint(model_path):\n",
    "    if model_path:\n",
    "        if os.path.isfile(model_path):\n",
    "            print(\"=> loading checkpoint '{}'\".format(model_path))\n",
    "            checkpoint = torch.load(model)\n",
    "            best_prec1 = checkpoint['best_prec1']\n",
    "            model.load_state_dict(checkpoint['state_dict'])\n",
    "            print(\"=> loaded checkpoint '{}' (epoch {}) Prec1: {:f}\"\n",
    "              .format(model_path, checkpoint['epoch'], best_prec1))\n",
    "        else:\n",
    "            raise ValueError(\"=> no checkpoint found at '{}'\".format(model_path))\n",
    "    else:\n",
    "        raise ValueError('args.model cannot be empty!')\n",
    "    return best_prec1 \n",
    "\n",
    "def test(model):\n",
    "    model.eval()\n",
    "    model.cuda()\n",
    "    test_loss = 0\n",
    "    correct = 0\n",
    "    with torch.no_grad():\n",
    "        for data, target in test_loader:\n",
    "            if torch.cuda.is_available():\n",
    "                data, target = data.cuda(), target.cuda()\n",
    "            output = model(data)\n",
    "            test_loss += F.cross_entropy(output, target, reduction='sum').data # sum up batch loss\n",
    "            pred = output.data.max(1, keepdim=True)[1] # get the index of the max log-probability\n",
    "            correct += pred.eq(target.data.view_as(pred)).cpu().sum().item()\n",
    "\n",
    "    test_loss /= len(test_loader.dataset)\n",
    "    print('Test set: Average loss: {:f}, Accuracy: {}/{} ({:.2f}%)'.format(\n",
    "        test_loss, correct, len(test_loader.dataset),\n",
    "        100. * correct / len(test_loader.dataset)))\n",
    "    return correct / float(len(test_loader.dataset))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=> loaded checkpoint '/home/hguan2/workspace/fault-tolerance/rethinking-network-pruning/cifar/l1-norm-pruning/logs/vgg16/cifar10/model_best.pth.tar' (epoch 158) Prec1: 0.938800\n"
     ]
    }
   ],
   "source": [
    "model_path = \"/home/hguan2/workspace/fault-tolerance/rethinking-network-pruning/cifar/l1-norm-pruning\"+ \\\n",
    "    \"/logs/vgg16/cifar10/model_best.pth.tar\"\n",
    "arch = 'vgg'\n",
    "depth = '16'\n",
    "dataset = 'cifar10'\n",
    "\n",
    "checkpoint = torch.load(model_path)\n",
    "model = models.__dict__[arch](dataset=dataset, depth=depth, cfg=checkpoint['cfg'])\n",
    "model.load_state_dict(checkpoint['state_dict'])\n",
    "best_prec1 = checkpoint['best_prec1']\n",
    "print(\"=> loaded checkpoint '{}' (epoch {}) Prec1: {:f}\"\n",
    "              .format(model_path, checkpoint['epoch'], best_prec1))\n",
    "# print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for param_name, param in model.named_parameters():\n",
    "#     if len(param.size()) < 2:\n",
    "#         continue\n",
    "#     plt.hist(param.data.cpu().numpy().ravel(), bins=100)\n",
    "#     plt.title(param_name + ': '+ str(param.size()))\n",
    "#     plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# prec1 = test() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for key, value in model.state_dict().items():\n",
    "#     print(key, value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finish parameter:feature.0.weight (64, 3, 3, 3)\n",
      "Finish parameter:feature.1.weight (64,)\n",
      "Finish parameter:feature.1.bias (64,)\n",
      "Finish parameter:feature.3.weight (64, 64, 3, 3)\n",
      "Finish parameter:feature.4.weight (64,)\n",
      "Finish parameter:feature.4.bias (64,)\n",
      "Finish parameter:feature.7.weight (128, 64, 3, 3)\n",
      "Finish parameter:feature.8.weight (128,)\n",
      "Finish parameter:feature.8.bias (128,)\n",
      "Finish parameter:feature.10.weight (128, 128, 3, 3)\n",
      "Finish parameter:feature.11.weight (128,)\n",
      "Finish parameter:feature.11.bias (128,)\n",
      "Finish parameter:feature.14.weight (256, 128, 3, 3)\n",
      "Finish parameter:feature.15.weight (256,)\n",
      "Finish parameter:feature.15.bias (256,)\n",
      "Finish parameter:feature.17.weight (256, 256, 3, 3)\n",
      "Finish parameter:feature.18.weight (256,)\n",
      "Finish parameter:feature.18.bias (256,)\n",
      "Finish parameter:feature.20.weight (256, 256, 3, 3)\n",
      "Finish parameter:feature.21.weight (256,)\n",
      "Finish parameter:feature.21.bias (256,)\n",
      "Finish parameter:feature.24.weight (512, 256, 3, 3)\n",
      "Finish parameter:feature.25.weight (512,)\n",
      "Finish parameter:feature.25.bias (512,)\n",
      "Finish parameter:feature.27.weight (512, 512, 3, 3)\n",
      "Finish parameter:feature.28.weight (512,)\n",
      "Finish parameter:feature.28.bias (512,)\n",
      "Finish parameter:feature.30.weight (512, 512, 3, 3)\n",
      "Finish parameter:feature.31.weight (512,)\n",
      "Finish parameter:feature.31.bias (512,)\n",
      "Finish parameter:feature.34.weight (512, 512, 3, 3)\n",
      "Finish parameter:feature.35.weight (512,)\n",
      "Finish parameter:feature.35.bias (512,)\n",
      "Finish parameter:feature.37.weight (512, 512, 3, 3)\n",
      "Finish parameter:feature.38.weight (512,)\n",
      "Finish parameter:feature.38.bias (512,)\n",
      "Finish parameter:feature.40.weight (512, 512, 3, 3)\n",
      "Finish parameter:feature.41.weight (512,)\n",
      "Finish parameter:feature.41.bias (512,)\n",
      "Finish parameter:classifier.0.weight (512, 512)\n",
      "Finish parameter:classifier.0.bias (512,)\n",
      "Finish parameter:classifier.1.weight (512,)\n",
      "Finish parameter:classifier.1.bias (512,)\n",
      "Finish parameter:classifier.3.weight (10, 512)\n",
      "Finish parameter:classifier.3.bias (10,)\n",
      "Finish bits manipulation in: 2233(s)\n"
     ]
    }
   ],
   "source": [
    "def copy_bits(n_LSB=16):  \n",
    "    def _copy_bits(v):\n",
    "        bits = bitstring.pack('>f', v)\n",
    "#         print('befor:', bits.bin, v)\n",
    "        # option 1: copy directly to the last LSBs\n",
    "        bits[32-n_LSB:32] = bits[:n_LSB]\n",
    "        \n",
    "        # option 2: copy sign bits to the last LSB\n",
    "#         bits[32-n_LSB:32] = bits[1:n_LSB]+bits[:1]\n",
    "        \n",
    "        # option 3: copy first 15 bits and then use the last 1 LSB for parity bit \n",
    "#         bits[32-n_LSB: 31] = bits[1:n_LSB-1] + bits[:1]\n",
    "#         bits[32] = (sum(c=='1' for c in bits[:31].bin)%2 == 1)\n",
    "#         print('after:', bits.bin, bits.float)\n",
    "        return bits.float\n",
    "    return _copy_bits\n",
    "    \n",
    "\n",
    "n_LSB = 16 # set the last n_LSB bits of mantisa to copy the MSB of exponents\n",
    "copy_fn = copy_bits(n_LSB)\n",
    "\n",
    "start = time.time()\n",
    "for name, parameter in model.named_parameters():\n",
    "    tensor = parameter.data.cpu().numpy()\n",
    "    tensor_shape = tensor.shape \n",
    "    tensor = np.array([copy_fn(v) for v in tensor.ravel()], dtype='float32')\n",
    "#     print(tensor)\n",
    "#     for i in range(len(tensor)):\n",
    "#         v = tensor[i]\n",
    "#         tensor[i] = copy_fn(v)\n",
    "#         break \n",
    "#     break \n",
    "    print('Finish parameter:'+name, str(tensor_shape))\n",
    "    parameter.data = torch.from_numpy(tensor.reshape(tensor_shape))\n",
    "end = time.time()\n",
    "print('Finish bits manipulation in: %d(s)' %(end-start))\n",
    "# prec1_1 = test()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test set: Average loss: 0.313613, Accuracy: 9388/10000 (93.88%)\n"
     ]
    }
   ],
   "source": [
    "prec1_1 = test(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.17978152632713318\n",
      "0.1801621913909912\n"
     ]
    }
   ],
   "source": [
    "# compare parameters with state_dict\n",
    "for name, parameter in model.named_parameters():\n",
    "    if name in checkpoint['state_dict']:\n",
    "        print(checkpoint['state_dict'][name].view(-1)[:1].sum().item())\n",
    "        print(parameter.data.view(-1)[:1].sum().item())\n",
    "        break "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# quantizer = distiller.quantization.PostTrainLinearQuantizer(model)\n",
    "# quantizer.prepare_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data, target = next(iter(test_loader))\n",
    "# print(model.feature[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for key, value in model.state_dict().items():\n",
    "#     print(key, value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# prec1 = test()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save_path = os.path.join(\"/\".join(model_path.split('/')[:-1]), 'quantize') \n",
    "# if not os.path.exists(save_path):\n",
    "#     os.makedirs(save_path)\n",
    "    \n",
    "# # save accuracy\n",
    "# with open(os.path.join(save_path, \"quantize.txt\"), \"w\") as fp:\n",
    "#     fp.write(\"Test accuracy: \\n\"+str(prec1)+\"\\n\")\n",
    "\n",
    "# # save quantized model     \n",
    "# torch.save({ 'cfg': model.cfg, \n",
    "#             'state_dict': model.state_dict(), \n",
    "#             'prec1': prec1\n",
    "#            }, os.path.join(save_path, 'quantized.pth.tar'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for  name, value in model.named_parameters():\n",
    "#     print(name, value.size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # check the weight distribution of other pre-trained models in torch vision\n",
    "# import torchvision \n",
    "\n",
    "# pretrained_models = {'resnet18': torchvision.models.resnet18(pretrained=True),\n",
    "#                      'alexnet': torchvision.models.alexnet(pretrained=True),\n",
    "#                      'squeezenet': torchvision.models.squeezenet1_0(pretrained=True),\n",
    "#                      'vgg16':  torchvision.models.vgg16(pretrained=True), \n",
    "#                      'densenet':  torchvision.models.densenet161(pretrained=True),\n",
    "#                      'inception_v3':  torchvision.models.inception_v3(pretrained=True),\n",
    "#                     }\n",
    "# for model_name, pretrained_model in pretrained_models.items():\n",
    "#     tensor = [param.data.cpu().numpy().ravel() for param in pretrained_model.parameters()]\n",
    "#     tensor = np.concatenate(tensor)\n",
    "#     minv, maxv = np.min(tensor), np.max(tensor)\n",
    "#     num_values = tensor.shape[0]\n",
    "#     plt.hist(tensor, bins=10000)\n",
    "#     plt.title(model_name+ ':[%f, %f], #=%.1f(M)' %(minv, maxv, num_values/10e6))\n",
    "#     plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
