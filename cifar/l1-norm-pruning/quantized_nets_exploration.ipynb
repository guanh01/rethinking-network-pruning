{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/hguan2/anaconda2/envs/distiller/lib/python3.5/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "using GPU: True\n"
     ]
    }
   ],
   "source": [
    "import distiller \n",
    "import numpy as np\n",
    "import os, collections\n",
    "import bitstring \n",
    "import time \n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.autograd import Variable\n",
    "from torchvision import datasets, transforms\n",
    "import torch.nn.functional as F\n",
    "import torchvision \n",
    "import models \n",
    "from matplotlib import pyplot as plt\n",
    "from eval_util import test_imagenet \n",
    "# import multiprocessing \n",
    "%matplotlib inline\n",
    "\n",
    "print('using GPU:', torch.cuda.is_available())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/hguan2/anaconda2/envs/distiller/lib/python3.5/site-packages/torchvision/models/squeezenet.py:94: UserWarning: nn.init.kaiming_uniform is now deprecated in favor of nn.init.kaiming_uniform_.\n",
      "  init.kaiming_uniform(m.weight.data)\n",
      "/home/hguan2/anaconda2/envs/distiller/lib/python3.5/site-packages/torchvision/models/squeezenet.py:92: UserWarning: nn.init.normal is now deprecated in favor of nn.init.normal_.\n",
      "  init.normal(m.weight.data, mean=0.0, std=0.01)\n",
      "/home/hguan2/anaconda2/envs/distiller/lib/python3.5/site-packages/torchvision/models/densenet.py:212: UserWarning: nn.init.kaiming_normal is now deprecated in favor of nn.init.kaiming_normal_.\n",
      "  nn.init.kaiming_normal(m.weight.data)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AlexNet(\n",
      "  (features): Sequential(\n",
      "    (0): Conv2d(3, 64, kernel_size=(11, 11), stride=(4, 4), padding=(2, 2))\n",
      "    (1): ReLU(inplace)\n",
      "    (2): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "    (3): Conv2d(64, 192, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
      "    (4): ReLU(inplace)\n",
      "    (5): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "    (6): Conv2d(192, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (7): ReLU(inplace)\n",
      "    (8): Conv2d(384, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (9): ReLU(inplace)\n",
      "    (10): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (11): ReLU(inplace)\n",
      "    (12): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  )\n",
      "  (classifier): Sequential(\n",
      "    (0): Dropout(p=0.5)\n",
      "    (1): Linear(in_features=9216, out_features=4096, bias=True)\n",
      "    (2): ReLU(inplace)\n",
      "    (3): Dropout(p=0.5)\n",
      "    (4): Linear(in_features=4096, out_features=4096, bias=True)\n",
      "    (5): ReLU(inplace)\n",
      "    (6): Linear(in_features=4096, out_features=1000, bias=True)\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "# check the weight distribution of other pre-trained models in torch vision\n",
    "# use resnet18, alexnet, vgg16 \n",
    "\n",
    "pretrained_models = {'resnet18': torchvision.models.resnet18(pretrained=True),\n",
    "                     'resnet34': torchvision.models.resnet34(pretrained=True),\n",
    "                     'alexnet': torchvision.models.alexnet(pretrained=True),\n",
    "                     'squeezenet': torchvision.models.squeezenet1_0(pretrained=True),\n",
    "                     'vgg16':  torchvision.models.vgg16(pretrained=True), \n",
    "                      'vgg16_bn':  torchvision.models.vgg16_bn(pretrained=True), \n",
    "                     'densenet':  torchvision.models.densenet161(pretrained=True),\n",
    "                     'inception_v3':  torchvision.models.inception_v3(pretrained=True),\n",
    "                    }\n",
    "# for model_name, pretrained_model in pretrained_models.items():\n",
    "#     tensor = [param.data.cpu().numpy().ravel() for param in pretrained_model.parameters()]\n",
    "#     tensor = np.concatenate(tensor)\n",
    "#     minv, maxv = np.min(tensor), np.max(tensor)\n",
    "#     num_values = tensor.shape[0]\n",
    "#     plt.hist(tensor, bins=10000)\n",
    "#     plt.title(model_name+ ':[%f, %f], #=%.1f(M)' %(minv, maxv, num_values/10e6))\n",
    "#     plt.show()\n",
    "\n",
    "model_name = 'alexnet'\n",
    "model = pretrained_models[model_name]\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(acc1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test: [  0/500]\tTime  1.249 ( 1.249)\tLoss 9.9806e-01 (9.9806e-01)\tAcc@1  80.00 ( 80.00)\tAcc@5  88.00 ( 88.00)\n",
      "Test: [ 10/500]\tTime  1.031 ( 1.116)\tLoss 1.5428e+00 (1.1033e+00)\tAcc@1  64.00 ( 74.09)\tAcc@5  82.00 ( 89.00)\n",
      "Test: [ 20/500]\tTime  0.981 ( 1.125)\tLoss 1.4201e+00 (1.3543e+00)\tAcc@1  50.00 ( 68.19)\tAcc@5  90.00 ( 86.43)\n",
      "Test: [ 30/500]\tTime  1.038 ( 1.108)\tLoss 2.6921e+00 (1.5994e+00)\tAcc@1  40.00 ( 62.74)\tAcc@5  71.00 ( 83.39)\n",
      "Test: [ 40/500]\tTime  0.995 ( 1.103)\tLoss 9.6465e-01 (1.6422e+00)\tAcc@1  79.00 ( 61.51)\tAcc@5  88.00 ( 82.98)\n",
      "Acc@1: 64.860, Acc@5: 84.640\n"
     ]
    }
   ],
   "source": [
    "valdir = '/home/hguan2/datasets/imagenet/val'\n",
    "acc1 = test_imagenet(model, valdir, num_batches=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AlexNet(\n",
      "  (features): Sequential(\n",
      "    (0): RangeLinearQuantParamLayerWrapper(\n",
      "      mode=SYMMETRIC, num_bits_acts=8, num_bits_params=8, num_bits_accum=32, clip_acts=False, per_channel_wts=False\n",
      "      preset_activation_stats=False\n",
      "      w_scale=135.7703, w_zero_point=0.0000\n",
      "      base_b_scale=45.2447, base_b_zero_point=0.0000\n",
      "      (wrapped_module): Conv2d(3, 64, kernel_size=(11, 11), stride=(4, 4), padding=(2, 2))\n",
      "    )\n",
      "    (1): ReLU(inplace)\n",
      "    (2): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "    (3): RangeLinearQuantParamLayerWrapper(\n",
      "      mode=SYMMETRIC, num_bits_acts=8, num_bits_params=8, num_bits_accum=32, clip_acts=False, per_channel_wts=False\n",
      "      preset_activation_stats=False\n",
      "      w_scale=57.0281, w_zero_point=0.0000\n",
      "      base_b_scale=254.3297, base_b_zero_point=0.0000\n",
      "      (wrapped_module): Conv2d(64, 192, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
      "    )\n",
      "    (4): ReLU(inplace)\n",
      "    (5): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "    (6): RangeLinearQuantParamLayerWrapper(\n",
      "      mode=SYMMETRIC, num_bits_acts=8, num_bits_params=8, num_bits_accum=32, clip_acts=False, per_channel_wts=False\n",
      "      preset_activation_stats=False\n",
      "      w_scale=148.4304, w_zero_point=0.0000\n",
      "      base_b_scale=229.7970, base_b_zero_point=0.0000\n",
      "      (wrapped_module): Conv2d(192, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    )\n",
      "    (7): ReLU(inplace)\n",
      "    (8): RangeLinearQuantParamLayerWrapper(\n",
      "      mode=SYMMETRIC, num_bits_acts=8, num_bits_params=8, num_bits_accum=32, clip_acts=False, per_channel_wts=False\n",
      "      preset_activation_stats=False\n",
      "      w_scale=326.9010, w_zero_point=0.0000\n",
      "      base_b_scale=89.0331, base_b_zero_point=0.0000\n",
      "      (wrapped_module): Conv2d(384, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    )\n",
      "    (9): ReLU(inplace)\n",
      "    (10): RangeLinearQuantParamLayerWrapper(\n",
      "      mode=SYMMETRIC, num_bits_acts=8, num_bits_params=8, num_bits_accum=32, clip_acts=False, per_channel_wts=False\n",
      "      preset_activation_stats=False\n",
      "      w_scale=561.8413, w_zero_point=0.0000\n",
      "      base_b_scale=52.8700, base_b_zero_point=0.0000\n",
      "      (wrapped_module): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    )\n",
      "    (11): ReLU(inplace)\n",
      "    (12): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  )\n",
      "  (classifier): Sequential(\n",
      "    (0): Dropout(p=0.5)\n",
      "    (1): RangeLinearQuantParamLayerWrapper(\n",
      "      mode=SYMMETRIC, num_bits_acts=8, num_bits_params=8, num_bits_accum=32, clip_acts=False, per_channel_wts=False\n",
      "      preset_activation_stats=False\n",
      "      w_scale=1804.5466, w_zero_point=0.0000\n",
      "      base_b_scale=1349.9022, base_b_zero_point=0.0000\n",
      "      (wrapped_module): Linear(in_features=9216, out_features=4096, bias=True)\n",
      "    )\n",
      "    (2): ReLU(inplace)\n",
      "    (3): Dropout(p=0.5)\n",
      "    (4): RangeLinearQuantParamLayerWrapper(\n",
      "      mode=SYMMETRIC, num_bits_acts=8, num_bits_params=8, num_bits_accum=32, clip_acts=False, per_channel_wts=False\n",
      "      preset_activation_stats=False\n",
      "      w_scale=1216.8192, w_zero_point=0.0000\n",
      "      base_b_scale=691.2797, base_b_zero_point=0.0000\n",
      "      (wrapped_module): Linear(in_features=4096, out_features=4096, bias=True)\n",
      "    )\n",
      "    (5): ReLU(inplace)\n",
      "    (6): RangeLinearQuantParamLayerWrapper(\n",
      "      mode=SYMMETRIC, num_bits_acts=8, num_bits_params=8, num_bits_accum=32, clip_acts=False, per_channel_wts=False\n",
      "      preset_activation_stats=False\n",
      "      w_scale=577.7387, w_zero_point=0.0000\n",
      "      base_b_scale=779.8414, base_b_zero_point=0.0000\n",
      "      (wrapped_module): Linear(in_features=4096, out_features=1000, bias=True)\n",
      "    )\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "# post train quantization \n",
    "quantizer = distiller.quantization.PostTrainLinearQuantizer(model)\n",
    "quantizer.prepare_model()\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test: [  0/500]\tTime  1.229 ( 1.229)\tLoss 1.0247e+00 (1.0247e+00)\tAcc@1  81.00 ( 81.00)\tAcc@5  88.00 ( 88.00)\n",
      "Test: [ 10/500]\tTime  0.999 ( 1.125)\tLoss 1.5532e+00 (1.1451e+00)\tAcc@1  67.00 ( 74.00)\tAcc@5  84.00 ( 89.00)\n",
      "Test: [ 20/500]\tTime  0.979 ( 1.129)\tLoss 1.4807e+00 (1.3883e+00)\tAcc@1  53.00 ( 68.00)\tAcc@5  90.00 ( 86.43)\n",
      "Test: [ 30/500]\tTime  1.033 ( 1.112)\tLoss 2.6967e+00 (1.6292e+00)\tAcc@1  39.00 ( 62.68)\tAcc@5  72.00 ( 83.35)\n",
      "Test: [ 40/500]\tTime  0.966 ( 1.105)\tLoss 1.0108e+00 (1.6735e+00)\tAcc@1  77.00 ( 61.46)\tAcc@5  87.00 ( 82.90)\n",
      "Acc@1: 64.800, Acc@5: 84.580\n"
     ]
    }
   ],
   "source": [
    "acc1 = test_imagenet(model, valdir, num_batches=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check the distribution of parameters \n",
    "# thr = 32\n",
    "# layer_id = 0 \n",
    "# for param_name, param in model.named_parameters():\n",
    "#     if len(param.size()) < 2:\n",
    "#         continue\n",
    "#     counter = collections.Counter(np.abs(param.data.cpu().numpy().ravel())//thr)\n",
    "#     tmp = sorted(counter.items(), key=lambda x: x[0])\n",
    "#     values, counts = zip(*tmp)\n",
    "#     percentages = [count/sum(list(counts)) for count in counts]\n",
    "#     bar = plt.bar(values, percentages)\n",
    "#     for rect in bar:\n",
    "#         height = rect.get_height()\n",
    "#         plt.text(rect.get_x() + rect.get_width()/2.0, height, '%.4f%%' %(height*100), ha='center', va='bottom')\n",
    "# #     print(['%.2f' %(p) for p in percentages])\n",
    "#     #plt.hist(param.data.cpu().numpy().ravel(), bins=10, density=True)\n",
    "#     plt.xticks(values, [str(int(v)*thr+thr) for v in values])\n",
    "#     plt.title('layer_id:'+str(layer_id) + ', '+ str(tuple(param.size())))\n",
    "# #     plt.grid()\n",
    "#     plt.ylim(0, 1.1)\n",
    "#     plt.show()\n",
    "#     layer_id += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#weights: 21779648 , #params: 21797672 percentage: 0.999173\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# check the distribution of parameters all weights\n",
    "thr = 32\n",
    "total_values, num_weights = 0, 0 \n",
    "counter = collections.Counter()\n",
    "for param_name, param in model.named_parameters():\n",
    "    total_values += param.nelement()\n",
    "    if len(param.size()) < 2:\n",
    "        continue\n",
    "    num_weights += param.nelement()\n",
    "    counter.update(collections.Counter(np.abs(param.data.cpu().numpy().ravel())//thr + 1))\n",
    "    \n",
    "tmp = sorted(counter.items(), key=lambda x: x[0])\n",
    "values, counts = zip(*tmp)\n",
    "total_weights = sum(list(counts))\n",
    "\n",
    "assert total_weights == num_weights\n",
    "print('#weights:', total_weights, ', #params:', total_values, 'percentage:', '%.6f' %(num_weights/total_values))\n",
    "\n",
    "percentages = [count/total_weights for count in counts]\n",
    "bar = plt.bar(values, percentages)\n",
    "for rect in bar:\n",
    "    height = rect.get_height()\n",
    "    plt.text(rect.get_x() + rect.get_width()/2.0, height, '%.4f%%' %(height*100), ha='center', va='bottom')\n",
    "#     print(['%.2f' %(p) for p in percentages])\n",
    "#plt.hist(param.data.cpu().numpy().ravel(), bins=10, density=True)\n",
    "plt.xticks(values, [str(int(v)*thr) for v in values])\n",
    "plt.title(model_name)\n",
    "#     plt.grid()\n",
    "plt.ylim(0, 1.1)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
